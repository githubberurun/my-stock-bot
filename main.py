import pandas as pd
import yfinance as yf
import time
import io
import requests
import re
import os
import json
import numpy as np
from datetime import datetime, timedelta
from google.genai import Client
import gspread
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload

# --- è¨­å®š ---
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
GOOGLE_SERVICE_ACCOUNT_JSON = os.environ.get('GOOGLE_SERVICE_ACCOUNT_JSON')
SPREADSHEET_ID = os.environ.get('SPREADSHEET_ID')

client = Client(api_key=GEMINI_API_KEY)
json_data = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
creds = Credentials.from_service_account_info(json_data, scopes=[
    'https://www.googleapis.com/auth/spreadsheets',
    'https://www.googleapis.com/auth/drive'
])

def get_latest_jpx_list():
    url = "https://www.jpx.co.jp/markets/statistics-equities/misc/tvdivq0000001vg2-att/data_j.xls"
    res = requests.get(url)
    with io.BytesIO(res.content) as f:
        df = pd.read_excel(f, engine='xlrd')
        df = df[['ã‚³ãƒ¼ãƒ‰', 'éŠ˜æŸ„å', 'å¸‚å ´ãƒ»å•†å“åŒºåˆ†', '33æ¥­ç¨®åŒºåˆ†']]
        df.columns = ['ã‚³ãƒ¼ãƒ‰', 'ç¤¾å', 'å¸‚å ´', 'æ¥­ç¨®']
    return df[df['å¸‚å ´'].str.contains('ãƒ—ãƒ©ã‚¤ãƒ |ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰|ã‚°ãƒ­ãƒ¼ã‚¹', na=False)].copy()

# --- 1. å…¨3800ç¤¾ã‚¹ã‚­ãƒ£ãƒ³ ---
df_all = get_latest_jpx_list()
print(f"ğŸ“¡ 3776ç¤¾ã®ã‚¹ã‚­ãƒ£ãƒ³é–‹å§‹...")
candidates = []
for i, (idx, row) in enumerate(df_all.iterrows()):
    ticker = f"{str(row['ã‚³ãƒ¼ãƒ‰']).strip()}.T"
    try:
        s = yf.Ticker(ticker)
        f = s.fast_info
        if f.get('last_price'):
            candidates.append({'ticker': ticker, 'row': row, 'mcap': f.get('market_cap', 0), 'price': f.get('last_price')})
    except: continue
target_list = sorted(candidates, key=lambda x: x['mcap'], reverse=True)[:200]

# --- 2. 200ç¤¾ã®ç²¾å¯†åˆ†æ ---
final_rows = []
header = ['æ—¥ä»˜', 'ã‚³ãƒ¼ãƒ‰', 'ç¤¾å', 'æˆ¦ç•¥', 'ç·åˆè©•ä¾¡', 'ç¾åœ¨å€¤', 'ç‚ºæ›¿ãƒ©ãƒ™ãƒ«', 'ãƒ¬ãƒ³ã‚¸ä¸Šé™', 'åˆ©å›ã‚Š', 'é…å½“æ€§å‘', 'ROE', 'PER', 'PBR', 'è‡ªå·±è³‡æœ¬æ¯”ç‡', 'FCF(ç™¾ä¸‡)', 'ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥', 'RSI', '25æ—¥ä¹–é›¢', 'AIæ·±å±¤è¨ºæ–­']
date_str = (datetime.utcnow() + timedelta(hours=9)).strftime("%Y-%m-%d")
start_time = time.time()

print(f"ğŸ¤– é¸æŠœ200ç¤¾ã®ã€Œå…¨æŒ‡æ¨™ã€åˆ†æã‚’é–‹å§‹ï¼ˆåˆ¶é™æ™‚é–“800ç§’ï¼‰...")

for i, item in enumerate(target_list):
    # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆå¯¾ç­–ï¼šçµ‚äº†100ç§’å‰ã«ã¯ä¿å­˜ã¸ç§»ã‚‹
    if time.time() - start_time > 750: 
        print("âš ï¸ å®Œé‚ã‚’å„ªå…ˆã—ã€ç¾æ™‚ç‚¹ã®ãƒ‡ãƒ¼ã‚¿ã§ä¿å­˜ã‚’é–‹å§‹ã—ã¾ã™ã€‚")
        break
    
    try:
        s = yf.Ticker(item['ticker'])
        inf = s.info
        hist = s.history(period="3mo")
        
        # æŒ‡æ¨™å–å¾—ï¼ˆæ•°å€¤ã¯floatåŒ–ã—ã¦å®‰å®šã•ã›ã‚‹ï¼‰
        roe = float(inf.get('returnOnEquity', 0)) * 100
        yld = float(inf.get('dividendYield', 0)) * 100
        per = float(inf.get('trailingPE', 0))
        pbr = float(inf.get('priceToBook', 0))
        payout = float(inf.get('payoutRatio', 0)) * 100
        eq_ratio = float(inf.get('equityRatio', 0)) * 100 if inf.get('equityRatio') else (float(inf.get('bookValue', 0)) / (float(inf.get('totalAssets', 1))) * 100)
        
        # æŒ‡ç¤ºé€šã‚Šã®è¨ˆç®—ï¼šFCF = å–¶æ¥­CF + æŠ•è³‡CF
        fcf = (float(inf.get('operatingCashflow', 0)) + float(inf.get('investingCashflow', 0))) / 1e6
        # æŒ‡ç¤ºé€šã‚Šã®è¨ˆç®—ï¼šãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥ = ç¾é é‡‘ - ç·è² å‚µ
        net_cash = (float(inf.get('totalCash', 0)) - float(inf.get('totalDebt', 0))) / 1e6
        
        # æŒ‡ç¤ºé€šã‚Šã®è¨ˆç®—ï¼šãƒ¬ãƒ³ã‚¸ä¸Šé™ = max(EPS*12, é…å½“é¡/0.04)
        eps = float(inf.get('trailingEps', 0))
        div_rate = float(inf.get('dividendRate', 0))
        upper_limit = max(eps * 12, div_rate / 0.04)

        # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«
        close = hist['Close']
        rsi, dev = 50.0, 0.0
        if len(close) >= 25:
            delta = close.diff(); gain = (delta.where(delta > 0, 0)).rolling(14).mean(); loss = (-delta.where(delta < 0, 0)).rolling(14).mean()
            rs = gain / loss.replace(0, np.nan)
            rsi = (100 - (100 / (1 + rs))).iloc[-1]
            ma25 = close.rolling(25).mean().iloc[-1]
            dev = ((close.iloc[-1] - ma25) / ma25) * 100

        # AIåˆ†æï¼ˆç‚ºæ›¿ãƒ©ãƒ™ãƒ«ã®æŒ‡ç¤ºã‚’å¼·åŒ–ï¼‰
        prompt = f"éŠ˜æŸ„:{item['row']['ç¤¾å']}, æ¥­ç¨®:{item['row']['æ¥­ç¨®']}, ROE:{roe:.1f}%ã€‚ç‚ºæ›¿å½±éŸ¿ã‚’å«ã‚ã€Œã‚¹ã‚³ã‚¢(-15ã€œ15)|ç‚ºæ›¿(å††å®‰æ©æµ/å††é«˜æ©æµ/ä¸­ç«‹)|è¨ºæ–­(40å­—)ã€ã§å›ç­”ã€‚"
        res = client.models.generate_content(model='gemini-2.0-flash', contents=prompt).text.strip()
        
        ai_score, ai_fx, ai_diag = 0, "ä¸­ç«‹", res
        if "|" in res:
            parts = res.split("|")
            ai_score = int(re.search(r'(-?\d+)', parts[0]).group(1)) if re.search(r'(-?\d+)', parts[0]) else 0
            ai_fx = parts[1].strip()
            ai_diag = parts[-1].strip()

        final_rows.append([
            date_str, item['row']['ã‚³ãƒ¼ãƒ‰'], item['row']['ç¤¾å'], "ä¸»åŠ›é¸æŠœ",
            int(50 + ai_score + (10 if roe > 10 else 0)), round(item['price'], 1), ai_fx, round(upper_limit, 1),
            round(yld, 2), round(payout, 1), round(roe, 1), round(per, 1), round(pbr, 2),
            round(eq_ratio, 1), round(fcf, 1), round(net_cash, 1), round(rsi, 1), round(dev, 1), ai_diag[:150]
        ])
        if (i+1) % 20 == 0: print(f"é€²è¡ŒçŠ¶æ³: {i+1}/200 åˆ†æå®Œäº†")
    except: continue

# --- 3. æ›¸ãè¾¼ã¿ ---
if final_rows:
    gc = gspread.authorize(creds); sh = gc.open_by_key(SPREADSHEET_ID)
    try: ws = sh.add_worksheet(title=date_str, rows="1000", cols="25", index=0)
    except: ws = sh.worksheet(date_str); ws.clear()
    ws.append_row(header)
    ws.append_rows(final_rows)
    
    drive_service = build('drive', 'v3', credentials=creds)
    csv_buf = io.BytesIO()
    pd.DataFrame(final_rows, columns=header).to_csv(csv_buf, index=False, encoding='utf-8-sig')
    media = MediaIoBaseUpload(csv_buf, mimetype='text/csv', resumable=True)
    for f in drive_service.files().list(q="name contains 'GitHubç”¨'").execute().get('files', []):
        drive_service.files().update(fileId=f['id'], media_body=media).execute()
    print(f"âœ¨ å…¨æŒ‡æ¨™ã‚’å®Œå…¨ç¶²ç¾…ã—ã€{len(final_rows)}ä»¶ã®æ›¸ãè¾¼ã¿ã‚’å®Œé‚ã—ã¾ã—ãŸã€‚")
