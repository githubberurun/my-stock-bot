import pandas as pd
import yfinance as yf
import time
import io
import requests
import re
import os
import json
import numpy as np
from datetime import datetime, timedelta
from google.genai import Client
import gspread
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload

# --- 1. èªè¨¼ ---
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
GOOGLE_SERVICE_ACCOUNT_JSON = os.environ.get('GOOGLE_SERVICE_ACCOUNT_JSON')
SPREADSHEET_ID = os.environ.get('SPREADSHEET_ID')

client = Client(api_key=GEMINI_API_KEY)
json_data = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
creds = Credentials.from_service_account_info(json_data, scopes=[
    'https://www.googleapis.com/auth/spreadsheets',
    'https://www.googleapis.com/auth/drive'
])

def get_latest_jpx_list():
    url = "https://www.jpx.co.jp/markets/statistics-equities/misc/tvdivq0000001vg2-att/data_j.xls"
    res = requests.get(url)
    with io.BytesIO(res.content) as f:
        df = pd.read_excel(f, engine='xlrd')
        df = df[['ã‚³ãƒ¼ãƒ‰', 'éŠ˜æŸ„å', 'å¸‚å ´ãƒ»å•†å“åŒºåˆ†', '33æ¥­ç¨®åŒºåˆ†']]
        df.columns = ['ã‚³ãƒ¼ãƒ‰', 'ç¤¾å', 'å¸‚å ´', 'æ¥­ç¨®']
    return df[df['å¸‚å ´'].str.contains('ãƒ—ãƒ©ã‚¤ãƒ |ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰|ã‚°ãƒ­ãƒ¼ã‚¹', na=False)].copy()

def calculate_technical(hist):
    if len(hist) < 25: return 50.0, 0.0
    close = hist['Close']
    # RSI
    delta = close.diff()
    gain = (delta.where(delta > 0, 0)).rolling(window=14).mean()
    loss = (-delta.where(delta < 0, 0)).rolling(window=14).mean()
    rs = gain / loss.replace(0, np.nan)
    rsi = (100 - (100 / (1 + rs))).iloc[-1]
    # 25æ—¥ä¹–é›¢
    ma25 = close.rolling(window=25).mean().iloc[-1]
    dev = ((close.iloc[-1] - ma25) / ma25) * 100
    return rsi, dev

# --- 2. 3800ç¤¾ãƒ•ãƒ«ã‚¹ã‚­ãƒ£ãƒ³ ---
df_all = get_latest_jpx_list()
print(f"ğŸ“¡ 3776ç¤¾ã®ã‚¹ã‚­ãƒ£ãƒ³ã‚’é–‹å§‹ï¼ˆå…¨15æŒ‡æ¨™ç¶²ç¾…ãƒ¢ãƒ¼ãƒ‰ï¼‰...")
candidates = []
for i, (idx, row) in enumerate(df_all.iterrows()):
    ticker = f"{str(row['ã‚³ãƒ¼ãƒ‰']).strip()}.T"
    try:
        s = yf.Ticker(ticker)
        f = s.fast_info
        if not f.get('last_price'): continue
        # ã‚¹ã‚­ãƒ£ãƒ³æ™‚ã¯æ™‚ä¾¡ç·é¡ï¼‹ROE(ç°¡æ˜“)ã§é¸æŠœ
        candidates.append({'ticker': ticker, 'row': row, 'mcap': f.get('market_cap', 0), 'price': f.get('last_price')})
    except: continue
    if (i+1) % 1000 == 0: print(f"SCAN: {i+1}ç¤¾å®Œäº†...")

target_list = sorted(candidates, key=lambda x: x['mcap'], reverse=True)[:200]

# --- 3. è©³ç´°åˆ†æï¼ˆ200ç¤¾ï¼‰ ---
final_rows = []
header = ['æ—¥ä»˜', 'ã‚³ãƒ¼ãƒ‰', 'ç¤¾å', 'æˆ¦ç•¥', 'ç·åˆè©•ä¾¡', 'ç¾åœ¨å€¤', 'ç‚ºæ›¿ãƒ©ãƒ™ãƒ«', 'ãƒ¬ãƒ³ã‚¸ä¸Šé™', 'åˆ©å›ã‚Š', 'é…å½“æ€§å‘', 'ROE', 'PER', 'PBR', 'è‡ªå·±è³‡æœ¬æ¯”ç‡', 'FCF(ç™¾ä¸‡)', 'ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥', 'RSI', '25æ—¥ä¹–é›¢', 'AIæ·±å±¤è¨ºæ–­']
date_str = (datetime.utcnow() + timedelta(hours=9)).strftime("%Y-%m-%d")

print(f"ğŸ¤– é¸æŠœ200ç¤¾ã®ç²¾å¯†åˆ†æã¨ç‚ºæ›¿åˆ¤æ–­ã‚’å®Ÿè¡Œä¸­...")
for item in target_list:
    try:
        s = yf.Ticker(item['ticker'])
        inf = s.info
        hist = s.history(period="3mo")
        
        # æŒ‡æ¨™å–å¾—
        roe = inf.get('returnOnEquity', 0) * 100
        yld = inf.get('dividendYield', 0) * 100
        per = inf.get('trailingPE', 0)
        pbr = inf.get('priceToBook', 0)
        payout = inf.get('payoutRatio', 0) * 100
        eq_ratio = inf.get('bookValue', 0) / (inf.get('totalAssets', 1)) * 100 if 'totalAssets' in inf else inf.get('equityRatio', 0)*100
        fcf = (inf.get('operatingCashflow', 0) or 0) + (inf.get('investingCashflow', 0) or 0)
        net_cash = (inf.get('totalCash', 0) or 0) - (inf.get('totalDebt', 0) or 0)
        eps = inf.get('trailingEps', 0)
        
        # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«
        rsi, dev = calculate_technical(hist)
        
        # ãƒ¬ãƒ³ã‚¸ä¸Šé™ç®—å‡º
        upper_limit = max(eps * 12, (inf.get('dividendRate', 0) or 0) / 0.04)

        # AIåˆ†æ
        prompt = f"éŠ˜æŸ„:{item['row']['ç¤¾å']}, æ¥­ç¨®:{item['row']['æ¥­ç¨®']}, ROE:{roe:.1f}%, FCF:{fcf/1e6:.0f}Mã€‚15æŒ‡æ¨™ã‹ã‚‰ã€Œã‚¹ã‚³ã‚¢(-15ã€œ15)|ç‚ºæ›¿(å††å®‰æ©æµ/å††é«˜æ©æµ/ä¸­ç«‹)|è¨ºæ–­(40å­—)ã€ã§å›ç­”ã€‚"
        res = client.models.generate_content(model='gemini-2.0-flash', contents=prompt).text.strip()
        
        # ãƒ‘ãƒ¼ã‚¹
        ai_score, ai_fx, ai_diag = 0, "ä¸­ç«‹", res.replace(",","ã€")
        if "|" in res:
            p = res.split("|")
            ai_score = int(re.search(r'(-?\d+)', p[0]).group(1)) if re.search(r'(-?\d+)', p[0]) else 0
            ai_fx = p[1].strip()
            ai_diag = p[-1].strip()

        # ç·åˆè©•ä¾¡ï¼ˆ50ç‚¹ãƒ™ãƒ¼ã‚¹ + AIã‚¹ã‚³ã‚¢ + è²¡å‹™åŠ ç‚¹ï¼‰
        total_score = int(min(100, max(0, 50 + ai_score + (10 if roe > 12 else 0) + (10 if fcf > 0 else 0))))

        final_rows.append([
            date_str, item['row']['ã‚³ãƒ¼ãƒ‰'], item['row']['ç¤¾å'], "ä¸»åŠ›é¸æŠœ",
            total_score, round(item['price'], 1), ai_fx, round(upper_limit, 1),
            round(yld, 2), round(payout, 1), round(roe, 1), round(per, 1), round(pbr, 2),
            round(eq_ratio, 1), round(fcf/1e6, 1), round(net_cash/1e6, 1), round(rsi, 1), round(dev, 1), ai_diag[:150]
        ])
        time.sleep(0.3)
    except: continue

# --- 4. å®Œé‚æ›¸ãè¾¼ã¿ ---
if final_rows:
    gc = gspread.authorize(creds)
    sh = gc.open_by_key(SPREADSHEET_ID)
    try: ws = sh.add_worksheet(title=date_str, rows="1000", cols="25", index=0)
    except: ws = sh.worksheet(date_str); ws.clear()
    ws.append_row(header)
    ws.append_rows(final_rows)

    drive_service = build('drive', 'v3', credentials=creds)
    csv_buf = io.BytesIO()
    pd.DataFrame(final_rows, columns=header).to_csv(csv_buf, index=False, encoding='utf-8-sig')
    media = MediaIoBaseUpload(csv_buf, mimetype='text/csv', resumable=True)
    query = "name contains 'GitHubç”¨' and trashed = false"
    files = drive_service.files().list(q=query).execute().get('files', [])
    for f in files:
        drive_service.files().update(fileId=f['id'], media_body=media).execute()
    print(f"âœ¨ å…¨19åˆ—ï¼ˆ15æŒ‡æ¨™ï¼‹ç‚ºæ›¿åˆ¤å®šï¼‰ã®200ç¤¾åˆ†æã‚’å®Œå…¨ã«å®Œé‚ã—ã¾ã—ãŸã€‚")
