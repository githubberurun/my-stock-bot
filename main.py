import pandas as pd
import yfinance as yf
import time
import io
import requests
import re
import os
import json
import numpy as np
from datetime import datetime, timedelta
from google.genai import Client
import gspread
from google.oauth2.service_account import Credentials
from googleapiclient.discovery import build
from googleapiclient.http import MediaIoBaseUpload

# --- è¨­å®š ---
GEMINI_API_KEY = os.environ.get('GEMINI_API_KEY')
GOOGLE_SERVICE_ACCOUNT_JSON = os.environ.get('GOOGLE_SERVICE_ACCOUNT_JSON')
SPREADSHEET_ID = os.environ.get('SPREADSHEET_ID') # IDã§ã®æŒ‡å®šã‚’å„ªå…ˆ

client = Client(api_key=GEMINI_API_KEY)
json_data = json.loads(GOOGLE_SERVICE_ACCOUNT_JSON)
creds = Credentials.from_service_account_info(json_data, scopes=[
    'https://www.googleapis.com/auth/spreadsheets', 'https://www.googleapis.com/auth/drive'
])

def get_latest_jpx_list():
    url = "https://www.jpx.co.jp/markets/statistics-equities/misc/tvdivq0000001vg2-att/data_j.xls"
    res = requests.get(url).content
    df = pd.read_excel(io.BytesIO(res), engine='xlrd')
    df = df[['ã‚³ãƒ¼ãƒ‰', 'éŠ˜æŸ„å', 'å¸‚å ´ãƒ»å•†å“åŒºåˆ†', '33æ¥­ç¨®åŒºåˆ†']]
    df.columns = ['ã‚³ãƒ¼ãƒ‰', 'ç¤¾å', 'å¸‚å ´', 'æ¥­ç¨®']
    return df[df['å¸‚å ´'].str.contains('ãƒ—ãƒ©ã‚¤ãƒ |ã‚¹ã‚¿ãƒ³ãƒ€ãƒ¼ãƒ‰|ã‚°ãƒ­ãƒ¼ã‚¹', na=False)].copy()

# --- 1. ã‚¹ã‚­ãƒ£ãƒ³ (200ç¤¾é¸æŠœ) ---
df_all = get_latest_jpx_list()
print("ğŸ“¡ å…¨3800ç¤¾ã‹ã‚‰ Blue-Chip ã¨ Deep Value å€™è£œã‚’æŠ½å‡º...")
tickers = [f"{str(c).strip()}.T" for c in df_all['ã‚³ãƒ¼ãƒ‰']]
selected_data = []

# æ™‚ä¾¡ç·é¡ä¸Šä½ã‹ã‚‰200ç¤¾ã‚’ç¢ºå®š
for i in range(0, 400, 100):
    batch = tickers[i:i+100]
    data = yf.download(batch, period="2d", group_by='ticker', threads=True, progress=False)
    for t in batch:
        try:
            h = data[t]
            if len(h) >= 2:
                p = float(h['Close'].iloc[-1])
                pc = float(h['Close'].iloc[-2])
                chg = ((p - pc) / pc) * 100
                row = df_all[df_all['ã‚³ãƒ¼ãƒ‰'] == int(t.split('.')[0])].iloc[0]
                selected_data.append({'ticker': t, 'row': row, 'price': p, 'change': f"{chg:+.2f}%"})
        except: continue
    if len(selected_data) >= 200: break

# --- 2. ç²¾å¯†åˆ†æ ---
final_rows = []
header = ['æ—¥ä»˜', 'ã‚³ãƒ¼ãƒ‰', 'ç¤¾å', 'æˆ¦ç•¥', 'ç·åˆè©•ä¾¡', 'ç¾åœ¨å€¤', 'å‰æ—¥æ¯”', 'ç‚ºæ›¿ãƒ©ãƒ™ãƒ«', 'ãƒ¬ãƒ³ã‚¸ä¸Šé™', 'åˆ©å›ã‚Š', 'é…å½“æ€§å‘', 'ROE', 'PER', 'PBR', 'è‡ªå·±è³‡æœ¬æ¯”ç‡', 'FCF(ç™¾ä¸‡)', 'ãƒãƒƒãƒˆã‚­ãƒ£ãƒƒã‚·ãƒ¥', 'RSI', '25æ—¥ä¹–é›¢', 'AIæ·±å±¤è¨ºæ–­']
date_str = (datetime.utcnow() + timedelta(hours=9)).strftime("%Y-%m-%d")

# ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆæ¥ç¶šï¼ˆIDå„ªå…ˆã€å¤±æ•—ã—ãŸã‚‰åå‰ã§æ¤œç´¢ï¼‰
gc = gspread.authorize(creds)
try:
    sh = gc.open_by_key(SPREADSHEET_ID)
except:
    try: sh = gc.open('Githubç”¨')
    except Exception as e:
        print(f"âŒ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã®æ¥ç¶šã«å¤±æ•—: {e}")
        exit()

try:
    ws = sh.add_worksheet(title=date_str, rows="1000", cols="25", index=0)
except:
    ws = sh.worksheet(date_str); ws.clear()
ws.append_row(header)

print("ğŸ¤– åˆ†æã‚’é–‹å§‹ã—ã¾ã™...")

for i, item in enumerate(selected_data[:200]):
    try:
        s = yf.Ticker(item['ticker'])
        inf = s.info
        hist = s.history(period="3mo")
        
        # æˆ¦ç•¥åã‚’å°‚é–€ç”¨èªã§ç¢ºå®š
        strategy = "Blue-Chip Strategy" if i < 100 else "Deep Value Strategy"
        
        # è²¡å‹™æŒ‡æ¨™ãƒ­ã‚¸ãƒƒã‚¯
        roe = float(inf.get('returnOnEquity', 0)) * 100
        yld = float(inf.get('dividendYield', 0)) * 100
        fcf = (float(inf.get('operatingCashflow', 0)) + float(inf.get('investingCashflow', 0))) / 1e6
        net_cash = (float(inf.get('totalCash', 0)) - float(inf.get('totalDebt', 0))) / 1e6
        eps = float(inf.get('trailingEps', 0))
        div_rate = float(inf.get('dividendRate', 0))
        upper_limit = max(eps * 12, div_rate / 0.04)

        # ãƒ†ã‚¯ãƒ‹ã‚«ãƒ«
        close = hist['Close']
        rsi, dev = 50.0, 0.0
        if len(close) >= 25:
            delta = close.diff(); g = delta.where(delta > 0, 0).rolling(14).mean(); l = -delta.where(delta < 0, 0).rolling(14).mean()
            rsi = (100 - (100 / (1 + (g/l.replace(0, np.nan))))).iloc[-1]
            dev = ((close.iloc[-1] - close.rolling(25).mean().iloc[-1]) / close.rolling(25).mean().iloc[-1]) * 100

        # AIåˆ†æ
        prompt = f"éŠ˜æŸ„:{item['row']['ç¤¾å']}, æ¥­ç¨®:{item['row']['æ¥­ç¨®']}, ROE:{roe:.1f}%ã€‚ç‚ºæ›¿å½±éŸ¿ã‚’å«ã‚ã€Œã‚¹ã‚³ã‚¢|ç‚ºæ›¿|è¨ºæ–­(40å­—)ã€ã§å›ç­”ã€‚"
        res = client.models.generate_content(model='gemini-2.0-flash', contents=prompt).text.strip()
        
        ai_s, ai_fx, ai_d = 0, "ä¸­ç«‹", res
        if "|" in res:
            p = res.split("|"); ai_s = int(re.search(r'(-?\d+)', p[0]).group(1)) if re.search(r'(-?\d+)', p[0]) else 0
            ai_fx, ai_d = p[1].strip(), p[-1].strip()

        final_rows.append([
            date_str, item['row']['ã‚³ãƒ¼ãƒ‰'], item['row']['ç¤¾å'], strategy,
            int(50 + ai_s), round(item['price'], 1), item['change'], ai_fx, round(upper_limit, 1),
            round(yld, 2), round(inf.get('payoutRatio', 0)*100, 1), round(roe, 1), round(inf.get('trailingPE', 0), 1), round(inf.get('priceToBook', 0), 2),
            round(inf.get('equityRatio', 0)*100 or 50, 1), round(fcf, 1), round(net_cash, 1), round(rsi, 1), round(dev, 1), ai_d[:150]
        ])
        
        if len(final_rows) % 10 == 0:
            ws.append_rows(final_rows[-10:])
            print(f"âœ… {len(final_rows)}/200 å®Œäº†")
    except: continue

# åŒæœŸ
drive_service = build('drive', 'v3', credentials=creds)
csv_buf = io.BytesIO()
pd.DataFrame(final_rows, columns=header).to_csv(csv_buf, index=False, encoding='utf-8-sig')
media = MediaIoBaseUpload(csv_buf, mimetype='text/csv', resumable=True)
files = drive_service.files().list(q="name contains 'GitHubç”¨' and trashed = false").execute().get('files', [])
for f in files:
    drive_service.files().update(fileId=f['id'], media_body=media).execute()
